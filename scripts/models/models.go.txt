// Code generated by groq-modeler DO NOT EDIT.
//
// groq-modeler Version 1.0.0

package groq

// Endpoint is the endpoint for the groq api.
// string
type Endpoint string

// Model is the type for models present on the groq api.
// string
type Model string

const (
	completionsSuffix     Endpoint = "/completions"
	chatCompletionsSuffix Endpoint = "/chat/completions"
	transcriptionsSuffix  Endpoint = "/audio/transcriptions"
	translationsSuffix    Endpoint = "/audio/translations"
	embeddingsSuffix      Endpoint = "/embeddings"
	moderationsSuffix     Endpoint = "/moderations"
	
	{{- range $model := .Models }}
		// {{ $model.Name }} is an AI {{if isTextModel $model}}text{{else}}audio{{end}} model provided by {{$model.OwnedBy}}. It has {{$model.ContextWindow}} context window.
		{{ $model.Name }} Model = "{{ $model.ID }}" {{- end }}
)

var disabledModelsForEndpoints = map[Endpoint]map[Model]bool{
	completionsSuffix: {
	{{- range $model := .Models }} {{ if isAudioModel $model }}
			{{ $model.Name }}: true, {{- end }} {{- end }} 
	},
	chatCompletionsSuffix: {
	{{- range $model := .Models }} {{ if isAudioModel $model }}
			{{ $model.Name }}: true, {{- end }} {{- end }}
	},
	transcriptionsSuffix: {
	{{- range $model := .Models }} {{ if isTextModel $model }}
			{{ $model.Name }}: true, {{- end }} {{- end }}
	},
	translationsSuffix: {
	{{- range $model := .Models }} {{ if isTextModel $model }}
			{{ $model.Name }}: true, {{- end }} {{- end }}
	},
	moderationsSuffix: {
	{{- range $model := .Models }} {{ if isModerationModel $model }}
			{{ $model.Name }}: true, {{- end }} {{- end }}
	},
}

func endpointSupportsModel(endpoint Endpoint, model Model) bool {
	return !disabledModelsForEndpoints[endpoint][model]
}


// Whisper Defines the models provided by OpenAI to use when processing audio with OpenAI.
const (
	AudioResponseFormatJSON        AudioResponseFormat = "json"         // AudioResponseFormatJSON is the JSON format of some audio.
	AudioResponseFormatText        AudioResponseFormat = "text"         // AudioResponseFormatText is the text format of some audio.
	AudioResponseFormatSRT         AudioResponseFormat = "srt"          // AudioResponseFormatSRT is the SRT format of some audio.
	AudioResponseFormatVerboseJSON AudioResponseFormat = "verbose_json" // AudioResponseFormatVerboseJSON is the verbose JSON format of some audio.
	AudioResponseFormatVTT         AudioResponseFormat = "vtt"          // AudioResponseFormatVTT is the VTT format of some audio.

	TranscriptionTimestampGranularityWord    TranscriptionTimestampGranularity = "word"    // TranscriptionTimestampGranularityWord is the word timestamp granularity.
	TranscriptionTimestampGranularitySegment TranscriptionTimestampGranularity = "segment" // TranscriptionTimestampGranularitySegment is the segment timestamp granularity.
)

// AudioResponseFormat is the response format for the audio API.
//
// Response formats; Whisper uses AudioResponseFormatJSON by default.
//
// string
type AudioResponseFormat string

// TranscriptionTimestampGranularity is the timestamp granularity for the transcription.
//
// string
type TranscriptionTimestampGranularity string
